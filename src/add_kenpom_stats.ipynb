{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ken Pom Stats\n",
    "- using the kenpompy library to load advanced stats that aren't in the Kaggle dataset\n",
    "- extracting height, experience, and off. and def. adjusted efficiency (which accounts for strength of schedule)\n",
    "- requires a kenpom subscription to run. Create a file `login.txt`, & put your account email in line 1 and password in line 2\n",
    "- this notebook creates the `data_2025/kp/` folder that is used in `data_preprocessing.ipynb` to add kenpom features to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../login.txt\", \"r\") as f:\n",
    "    email = f.readline().strip()\n",
    "    password = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kenpompy.summary import get_height, get_efficiency\n",
    "from kenpompy.utils import login\n",
    "import pandas as pd\n",
    "\n",
    "team_spellings = pd.read_csv(\"../data_2025/MTeamSpellings.csv\", encoding=\"Windows-1252\")\n",
    "team_spellings['TeamNameSpelling'] = team_spellings['TeamNameSpelling'].str.replace('.', '', regex=False).str.lower()\n",
    "team_spellings = team_spellings.drop_duplicates(subset=['TeamNameSpelling'], keep='first')\n",
    "\n",
    "years = [str(yr) for yr in range(2008, 2024)]\n",
    "browser = login(email, password)\n",
    "for yr in years:\n",
    "    all_data = pd.DataFrame()\n",
    "    height_df = get_height(browser, yr)[[\"Team\", \"AvgHgt\", \"EffHgt\", \"Experience\"]]\n",
    "    eff_df = get_efficiency(browser=browser, season=yr)[[\"Team\", \"Tempo-Adj\", \"Off. Efficiency-Adj\", \"Def. Efficiency-Adj\"]]\n",
    "    \n",
    "    # Merge height_df and eff_df on \"Team\" using an outer join\n",
    "    merged_df = pd.merge(height_df, eff_df, on=\"Team\", how=\"outer\")\n",
    "    \n",
    "    # Preprocess merged_df['Team']\n",
    "    merged_df['Team'] = merged_df['Team'].str.replace('.', '', regex=False).str.lower()\n",
    "    \n",
    "    # Standardize team names in merged_df using team_spellings\n",
    "    merged_df['Team'] = merged_df['Team'].map(team_spellings.set_index('TeamNameSpelling')['TeamID']).fillna(merged_df['Team'])\n",
    "\n",
    "    merged_df\n",
    "    all_data = pd.concat([all_data, merged_df], ignore_index = True)\n",
    "    all_data.to_csv(f\"../data_2025/kp/height-exp-eff-{yr}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"../data_2025/kp/\"\n",
    "team_names = set()\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            if \"Team\" in df.columns:\n",
    "                team_names.update(df[\"Team\"].tolist())\n",
    "            else:\n",
    "                print(f\"Warning: 'Team' column not found in {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual dictionary of team -> ids for where the auto mapping failed\n",
    "m = {\"arkansas pine bluff\": 1115, \"bethune cookman\": 1126, \"cal st bakersfield\": 1167, \"illinois chicago\": 1227, \"liu\": 1254, \"louisiana monroe\": 1419, \"texas a&m corpus chris\": 1394}\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"Team\"] = df[\"Team\"].replace(m)  # Replace team names with IDs\n",
    "    df.to_csv(filepath, index=False)  # Save the modified DataFrame back to the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "march_madness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
